{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only once.\n",
    "# Downloading `d3rlpy` package from source.\n",
    "\n",
    "!pip3 install gym Cython numpy opencv-python seaborn scikit-learn PyOpenGL\n",
    "!git clone https://github.com/takuseno/d3rlpy d3rlpy_GitHub\n",
    "!pip3 install -e d3rlpy_GitHub/\n",
    "!mv d3rlpy_GitHub/d3rlpy .\n",
    "!rm -rf d3rlpy_GitHub/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflection of modifications:\n",
    "# We will implement SAM optimizer into this package.\n",
    "\n",
    "!cp -rf changes/algos/* d3rlpy/algos/\n",
    "!rm -rf changes/algos/\n",
    "!mv -f changes/* d3rlpy/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d3rlpy\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cartpole.pkl into d3rlpy_data/cartpole_replay_v1.1.0.h5...\n"
     ]
    }
   ],
   "source": [
    "dataset, env = d3rlpy.datasets.get_cartpole()\n",
    "task_name='Cartpole'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1265, 317)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_episodes, test_episodes = train_test_split(dataset, test_size=0.2)\n",
    "len(train_episodes), len(test_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (41,) 41\n"
     ]
    }
   ],
   "source": [
    "epi0 = train_episodes[0]\n",
    "print(epi0.observations.shape, epi0.actions.shape, len(epi0.transitions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d3rlpy.algos import DoubleDQN, DiscreteSAC, DiscreteBCQ, DiscreteCQL\n",
    "from d3rlpy.models.optimizers import OptimizerFactory\n",
    "import torch\n",
    "from torch.optim import SGD, Adam\n",
    "from sam import SAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "kwargs_lr = dict(\n",
    "    learning_rate=lr,\n",
    "    temp_learning_rate=lr,\n",
    "    actor_learning_rate=lr,\n",
    "    critic_learning_rate=lr,\n",
    "    alpha_learning_rate=lr,\n",
    "    imitator_learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "\n",
    "# If you want SAM optimizer, uncomment the line below.\n",
    "# Notice: `base_optimizer` must be a `str`\n",
    "#opt_factory = OptimizerFactory(optim_cls=SAM, base_optimizer=\"SGD\", rho=0.05)\n",
    "\n",
    "# If you want other optimizer, use the line below.\n",
    "opt_factory = OptimizerFactory(optim_cls=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adam'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_name = opt_factory._optim_cls.__name__\n",
    "if opt_name == 'SAM':\n",
    "    opt_name += '_'+opt_factory._optim_kwargs['base_optimizer']\n",
    "opt_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:04:23 [warning  ] Unused arguments are passed.   actor_learning_rate=0.0001 alpha_learning_rate=0.0001 critic_learning_rate=0.0001 imitator_learning_rate=0.0001 temp_learning_rate=0.0001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DiscreteCQL'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare algorithm\n",
    "model = d3rlpy.algos.DiscreteCQL(\n",
    "    use_gpu=False,              # Using GPU or not\n",
    "    optim_factory=opt_factory,  # optimizer\n",
    "    **kwargs_lr                 # set learning rates (can cause some warning but it is OK)\n",
    ")\n",
    "\n",
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use pretrained model, change it to the name: e.g., 'd3rlpy_logs/DiscreteCQL_Adam_20221129131616/model_5020.pt'\n",
    "\n",
    "model_checkpoint_path = None\n",
    "if model_checkpoint_path:\n",
    "    model.build_with_env(env)\n",
    "    model.load_model(model_checkpoint_path)\n",
    "    d3rlpy.metrics.evaluate_on_environment(env)(model)  # deploy on the environment. (may output different results by each run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:04:24 [debug    ] RoundIterator is selected.\n",
      "2022-11-29 16:04:24 [info     ] Directory is created at d3rlpy_logs/DiscreteCQL_Adam_20221129160424\n",
      "2022-11-29 16:04:24 [debug    ] Building models...\n",
      "2022-11-29 16:04:24 [debug    ] Models have been built.\n",
      "2022-11-29 16:04:24 [info     ] Parameters are saved to d3rlpy_logs/DiscreteCQL_Adam_20221129160424/params.json params={'action_scaler': None, 'alpha': 1.0, 'batch_size': 32, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'gamma': 0.99, 'generated_maxlen': 100000, 'learning_rate': 0.0001, 'n_critics': 1, 'n_frames': 1, 'n_steps': 1, 'optim_factory': {'optim_cls': 'Adam'}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'real_ratio': 1.0, 'reward_scaler': None, 'scaler': None, 'target_update_interval': 8000, 'use_gpu': None, 'algorithm': 'DiscreteCQL', 'observation_shape': (4,), 'action_size': 2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c72670378f844bd898f835abd9796dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/2:   0%|          | 0/2522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:04:30 [info     ] DiscreteCQL_Adam_20221129160424: epoch=1 step=2522 epoch=1 metrics={'time_sample_batch': 5.0462776474495147e-05, 'time_algorithm_update': 0.0019154307579445896, 'loss': 0.6789304184166804, 'time_step': 0.0020183654742804338, 'environment': 200.0, 'td_error': 1.1924059022242497, 'advantage': -3.3904248963698085, 'value_scale': 1.1119657761956516} step=2522\n",
      "2022-11-29 16:04:30 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteCQL_Adam_20221129160424/model_2522.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9190081c216403d9ecaf97d664e347e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/2:   0%|          | 0/2522 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:04:36 [info     ] DiscreteCQL_Adam_20221129160424: epoch=2 step=5044 epoch=2 metrics={'time_sample_batch': 4.409079888243225e-05, 'time_algorithm_update': 0.0019012997776246278, 'loss': 0.6657996094245744, 'time_step': 0.0019914517792135266, 'environment': 200.0, 'td_error': 1.200659126589767, 'advantage': -3.4002273799498743, 'value_scale': 1.109628295481205} step=5044\n",
      "2022-11-29 16:04:36 [info     ] Model parameters are saved to d3rlpy_logs/DiscreteCQL_Adam_20221129160424/model_5044.pt\n",
      "\n",
      "EVALUATION SCORE:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(\n",
    "    train_episodes,\n",
    "    eval_episodes=test_episodes,\n",
    "    experiment_name=model.__class__.__name__+'_'+opt_name,\n",
    "    n_epochs=2,\n",
    "    scorers={\n",
    "        'environment': d3rlpy.metrics.evaluate_on_environment(env),\n",
    "        'td_error': d3rlpy.metrics.td_error_scorer,                     # smaller is better\n",
    "        'advantage': d3rlpy.metrics.discounted_sum_of_advantage_scorer, # smaller is better\n",
    "        'value_scale': d3rlpy.metrics.average_value_estimation_scorer   # smaller is better\n",
    "    },\n",
    "    tensorboard_dir='./tensorboard',\n",
    ")\n",
    "\n",
    "# Simple deployment\n",
    "print(\"\\nEVALUATION SCORE:\")\n",
    "d3rlpy.metrics.evaluate_on_environment(env)(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see tensorboard:\n",
    "%tensorboard --logdir=tensorboard/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill 74067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring (not completely implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d3rlpy.envs import Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = './video'\n",
    "frame_rate = 60\n",
    "record_rate = 1\n",
    "n_episodes = 3\n",
    "epsilon = 0.\n",
    "algo = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(out):\n",
    "    os.rmdir(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'glPushMatrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb 셀 25\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wrapped_env \u001b[39m=\u001b[39m Monitor(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     env,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb#X43sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     out,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     record_rate\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(record_rate),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb#X43sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# run episodes\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hanseul_jo/Desktop/OfflineRL_SAM/offlineRL_Cartpole.ipynb#X43sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m d3rlpy\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mevaluate_on_environment(wrapped_env, n_episodes, epsilon\u001b[39m=\u001b[39;49mepsilon)(algo)\n",
      "File \u001b[0;32m~/Desktop/OfflineRL_SAM/d3rlpy/metrics/scorer.py:474\u001b[0m, in \u001b[0;36mevaluate_on_environment.<locals>.scorer\u001b[0;34m(algo, *args)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m         action \u001b[39m=\u001b[39m algo\u001b[39m.\u001b[39mpredict([observation])[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 474\u001b[0m observation, reward, done, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(action)\n\u001b[1;32m    475\u001b[0m episode_reward \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m reward\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m is_image:\n",
      "File \u001b[0;32m~/Desktop/OfflineRL_SAM/d3rlpy/envs/wrappers.py:326\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    322\u001b[0m obs, reward, done, info \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_video_callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_episode):  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     \u001b[39m# store rendering\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     frame \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(\u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mrender(\u001b[39m\"\u001b[39;49m\u001b[39mrgb_array\u001b[39;49m\u001b[39m\"\u001b[39;49m), cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer\u001b[39m.\u001b[39mappend(frame)\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_episode_step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/RL/lib/python3.10/site-packages/gym/core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/RL/lib/python3.10/site-packages/gym/core.py:295\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrender\u001b[39m(\u001b[39mself\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mrender(mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/RL/lib/python3.10/site-packages/gym/envs/classic_control/cartpole.py:229\u001b[0m, in \u001b[0;36mCartPoleEnv.render\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcarttrans\u001b[39m.\u001b[39mset_translation(cartx, carty)\n\u001b[1;32m    227\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoletrans\u001b[39m.\u001b[39mset_rotation(\u001b[39m-\u001b[39mx[\u001b[39m2\u001b[39m])\n\u001b[0;32m--> 229\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mviewer\u001b[39m.\u001b[39;49mrender(return_rgb_array\u001b[39m=\u001b[39;49mmode \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mrgb_array\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/RL/lib/python3.10/site-packages/gym/envs/classic_control/rendering.py:126\u001b[0m, in \u001b[0;36mViewer.render\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow\u001b[39m.\u001b[39mswitch_to()\n\u001b[1;32m    125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow\u001b[39m.\u001b[39mdispatch_events()\n\u001b[0;32m--> 126\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform\u001b[39m.\u001b[39;49menable()\n\u001b[1;32m    127\u001b[0m \u001b[39mfor\u001b[39;00m geom \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgeoms:\n\u001b[1;32m    128\u001b[0m     geom\u001b[39m.\u001b[39mrender()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/RL/lib/python3.10/site-packages/gym/envs/classic_control/rendering.py:232\u001b[0m, in \u001b[0;36mTransform.enable\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39menable\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 232\u001b[0m     glPushMatrix()\n\u001b[1;32m    233\u001b[0m     glTranslatef(\n\u001b[1;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranslation[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtranslation[\u001b[39m1\u001b[39m], \u001b[39m0\u001b[39m\n\u001b[1;32m    235\u001b[0m     )  \u001b[39m# translate to GL loc ppint\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     glRotatef(RAD2DEG \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrotation, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1.0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glPushMatrix' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "\n",
    "wrapped_env = Monitor(\n",
    "    env,\n",
    "    out,\n",
    "    video_callable=lambda ep: ep % 1 == 0,\n",
    "    frame_rate=float(frame_rate),\n",
    "    record_rate=int(record_rate),\n",
    ")\n",
    "\n",
    "# run episodes\n",
    "d3rlpy.metrics.evaluate_on_environment(wrapped_env, n_episodes, epsilon=epsilon)(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from pyglet.gl import glPushMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):  # three different experiments\n",
    "    print(\"\\n\\n############ Train/Test split #############\\n\")\n",
    "    train_episodes, test_episodes = train_test_split(dataset, test_size=0.2) # New split.\n",
    "    for algorithm in [DoubleDQN, DiscreteSAC, DiscreteBCQ, DiscreteCQL]:\n",
    "        for opt in [Adam, SGD]:\n",
    "            for use_SAM in [False, True]:\n",
    "                # Choose optimizer factory & optimizer name\n",
    "                if use_SAM:\n",
    "                    opt_factory = OptimizerFactory(optim_cls=SAM, base_optimizer=opt.__name__, rho=0.05)\n",
    "                    opt_name = 'SAM_'+opt.__name__\n",
    "                else:\n",
    "                    opt_factory = OptimizerFactory(optim_cls=opt)\n",
    "                    opt_name = opt.__name__\n",
    "                \n",
    "                # algorithm\n",
    "                model = algorithm(use_gpu=False, optim_factory=opt_factory, **kwargs_lr)\n",
    "                # train & evaluate\n",
    "                model.fit(\n",
    "                    train_episodes,\n",
    "                    eval_episodes=test_episodes,\n",
    "                    experiment_name=model.__class__.__name__+'_'+opt_name,\n",
    "                    n_epochs=16,\n",
    "                    scorers={\n",
    "                        'environment': d3rlpy.metrics.evaluate_on_environment(env),\n",
    "                        'td_error': d3rlpy.metrics.td_error_scorer, # smaller is better\n",
    "                        'advantage': d3rlpy.metrics.discounted_sum_of_advantage_scorer, # smaller is better\n",
    "                        'value_scale': d3rlpy.metrics.average_value_estimation_scorer # smaller is better\n",
    "                    },\n",
    "                    tensorboard_dir=f\"tensorboard/{task_name}/{model.__class__.__name__}/{opt_name}/\",\n",
    "                    verbose=False,\n",
    "                    show_progress=False\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('RL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9f500fbd88da4ca9935dd262491c6556111d12d087e6d2d75852c745d7ee377"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
